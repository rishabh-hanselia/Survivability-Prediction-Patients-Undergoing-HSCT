{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321ffb58",
   "metadata": {},
   "source": [
    "##    \n",
    "# Prediction Of Survivability of Children undergoing HSCT - Experiment I\n",
    "##   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e4dc1",
   "metadata": {},
   "source": [
    "###  \n",
    "## Importing Required Libraries\n",
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666cfc4b",
   "metadata": {},
   "source": [
    "###  \n",
    "## Reading CSV File (Dataset)\n",
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/rishabh's space/IIIT BHAGALPUR M.TECH/Course Work Assignments and Various Files/FInal Year project/major project 1/dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de5469",
   "metadata": {},
   "source": [
    "## Info about dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3edf3d6",
   "metadata": {},
   "source": [
    "### Size of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae6457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f17b1",
   "metadata": {},
   "source": [
    "### Info about features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55120625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc1862",
   "metadata": {},
   "source": [
    "### Checking NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fdf5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfe650d",
   "metadata": {},
   "source": [
    "### Checking number of unique values for object type features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17799f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "{column: len(df[column].unique()) for column in df.select_dtypes('object').columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe5b718",
   "metadata": {},
   "source": [
    "### Listing of unique values for object type features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae851050",
   "metadata": {},
   "outputs": [],
   "source": [
    "{column: list(df[column].unique()) for column in df.select_dtypes('object').columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9551ec5a",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf3b77b",
   "metadata": {},
   "source": [
    "### Selecting features having object type as their datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a6e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=df.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377122f",
   "metadata": {},
   "source": [
    "### Listing out the features having object datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4bb0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e567de",
   "metadata": {},
   "source": [
    "### Dropping the rows having '?' as their value (removing missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16507ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in columns:\n",
    "    df=df[df[i] != '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfdee94",
   "metadata": {},
   "source": [
    "### Checking the new size of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e09b9",
   "metadata": {},
   "source": [
    "### Checking number of unique values for object type features (checking removal of '?' as value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cfd2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "{column: len(df[column].unique()) for column in df.select_dtypes('object').columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2712c6",
   "metadata": {},
   "source": [
    "### Listing of unique values for object type features (checking removal of '?' as value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35fb044",
   "metadata": {},
   "outputs": [],
   "source": [
    "{column: list(df[column].unique()) for column in df.select_dtypes('object').columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f11a87",
   "metadata": {},
   "source": [
    "### Creating a custom function to convert datatype for features having numerical type values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979304c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_covertor(x):\n",
    "    if x == '?':\n",
    "        return 0\n",
    "    else: return float(x)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b0f6d6",
   "metadata": {},
   "source": [
    "### Converting values from object to numerical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recipient_body_mass'] = df['recipient_body_mass'].apply(type_covertor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a12aa2",
   "metadata": {},
   "source": [
    "### Checking the change of datatype for the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadcc647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afffeab7",
   "metadata": {},
   "source": [
    "### Converting values from object to numerical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CD3_x1e8_per_kg'] = df['CD3_x1e8_per_kg'].apply(type_covertor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca81446",
   "metadata": {},
   "source": [
    "### Checking the change of datatype for the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64db6a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63439d73",
   "metadata": {},
   "source": [
    "### Converting values from object to numerical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17961d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CD3_to_CD34_ratio'] = df['CD3_to_CD34_ratio'].apply(type_covertor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b509a505",
   "metadata": {},
   "source": [
    "### Checking the change of datatype for the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10614179",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbf0f40",
   "metadata": {},
   "source": [
    "### Listing of unique values for object type features (checking for the remaining object type features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "{column: list(df[column].unique()) for column in df.select_dtypes('object').columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7183c0",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3421f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= {column: len(df[column].unique()) == 2 for column in df.select_dtypes('object').columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73198a0f",
   "metadata": {},
   "source": [
    "### Selecting features having binary type values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bad2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary=[]\n",
    "for i in x:\n",
    "    if x[i] == True:\n",
    "        binary.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61369ba6",
   "metadata": {},
   "source": [
    "### Binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb7f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_binary(x):\n",
    "    if x == 'no':\n",
    "        return 0\n",
    "    elif x == 'yes':\n",
    "        return 1\n",
    "    elif x ==\"present\":\n",
    "        return 1\n",
    "    elif x =='absent':\n",
    "        return 0\n",
    "    elif x ==\"female\":\n",
    "        return 0\n",
    "    elif x =='male':\n",
    "        return 1\n",
    "    elif x ==\"minus\":\n",
    "        return 0\n",
    "    elif x =='plus':\n",
    "        return 1\n",
    "    elif x ==\"nonmalignant\":\n",
    "        return 0\n",
    "    elif x =='malignant':\n",
    "        return 1\n",
    "    elif x ==\"other\":\n",
    "        return 0\n",
    "    elif x =='female_to_male':\n",
    "        return 1\n",
    "    elif x ==\"mismatched\":\n",
    "        return 0\n",
    "    elif x =='matched':\n",
    "        return 1\n",
    "    elif x ==\"low\":\n",
    "        return 0\n",
    "    elif x =='high':\n",
    "        return 1\n",
    "    elif x ==\"peripheral_blood\":\n",
    "        return 0\n",
    "    elif x =='bone_marrow':\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in binary:\n",
    "    df[i] = df[i].apply(encode_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6474e8f8",
   "metadata": {},
   "source": [
    "### Checking the change of datatype for the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9dd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e16b4",
   "metadata": {},
   "source": [
    "### Listing of unique values for object type features (checking for the remaining object type features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df48d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "{column: list(df[column].unique()) for column in df.select_dtypes('object').columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7887d5",
   "metadata": {},
   "source": [
    "### Selecting features having nominal type values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal=['donor_ABO','recipient_ABO','disease','HLA_group_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf91417",
   "metadata": {},
   "source": [
    "### Selecting features having ordinal type values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b4173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal=['recipient_age_int','HLA_match']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d34d8b",
   "metadata": {},
   "source": [
    "### Selecting features having numerical type values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numercical=['CMV_status','antigen','allel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ab1635",
   "metadata": {},
   "source": [
    "### Custom function for converting datatype to numerical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a9bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_type_covertor(x):\n",
    "    if x == '?':\n",
    "        return 0\n",
    "    else: return int(x)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f94b4",
   "metadata": {},
   "source": [
    "### Converting values from object to numerical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58bf842",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numercical:\n",
    "    df[i] = df[i].apply(int_type_covertor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a54e8",
   "metadata": {},
   "source": [
    "### Checking the change of datatype for the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1cf197",
   "metadata": {},
   "source": [
    "### One-Hot Encoding for features have ordinal type values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42226f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ordinal:\n",
    "    df = pd.get_dummies(df, prefix=[i], columns=[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ef86d",
   "metadata": {},
   "source": [
    "### Checking the new size of dataframes (Increasae in number of features due to One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae5ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05bf591",
   "metadata": {},
   "source": [
    "### Checking the change of datatype for the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d4dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973d0205",
   "metadata": {},
   "source": [
    "### One-Hot Encoding for features have nominal type values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d485f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nominal:\n",
    "    df = pd.get_dummies(df, prefix=[i], columns=[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b4c235",
   "metadata": {},
   "source": [
    "### Checking the new size of dataframes (Increasae in number of features due to One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02382356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725bc8f",
   "metadata": {},
   "source": [
    "### Checking the change of datatype for the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b454646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b2dcf",
   "metadata": {},
   "source": [
    "###  \n",
    "## Model Building\n",
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['survival_status'], axis = 1)\n",
    "y = df['survival_status'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de01cf",
   "metadata": {},
   "source": [
    "###  \n",
    "### Splitting the dataset into train:80% and test:20%\n",
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e325a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 0 , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c93a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b806a6",
   "metadata": {},
   "source": [
    "###  \n",
    "### Lists to hold the values to be printed\n",
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_comp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb46293",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_comp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d3c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_comp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d51290",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score_comp = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df08cd3c",
   "metadata": {},
   "source": [
    "## Models/Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4df338",
   "metadata": {},
   "source": [
    "###  \n",
    "## Logistic Regression\n",
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4462de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "predictions = lr.predict(x_test)\n",
    "\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, predictions))\n",
    "print('\\nClassification Report:\\n\\n',classification_report(y_test, predictions))\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "prec = precision_score(y_test, predictions)\n",
    "rec = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "acc_perc = np.round(acc*100, 2)\n",
    "print('\\nAccuracy=',str(acc_perc)+'%')\n",
    "\n",
    "accuracy_comp.append(acc_perc)\n",
    "precision_comp.append(prec)\n",
    "recall_comp.append(rec)\n",
    "f1score_comp.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ec1757",
   "metadata": {},
   "source": [
    "###  \n",
    "## Decision Tree Classifier\n",
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf1b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)\n",
    "predictions = dt.predict(x_test)\n",
    "\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, predictions))\n",
    "print('\\nClassification Report:\\n\\n',classification_report(y_test, predictions))\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "prec = precision_score(y_test, predictions)\n",
    "rec = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "acc_perc = np.round(acc*100, 2)\n",
    "print('\\nAccuracy=',str(acc_perc)+'%')\n",
    "\n",
    "accuracy_comp.append(acc_perc)\n",
    "precision_comp.append(prec)\n",
    "recall_comp.append(rec)\n",
    "f1score_comp.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21757527",
   "metadata": {},
   "source": [
    "###  \n",
    "## Random Forest Classifier\n",
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8568e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)\n",
    "predictions = rf.predict(x_test)\n",
    "\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, predictions))\n",
    "print('\\nClassification Report:\\n\\n',classification_report(y_test, predictions))\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "prec = precision_score(y_test, predictions)\n",
    "rec = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "acc_perc = np.round(acc*100, 2)\n",
    "print('\\nAccuracy=',str(acc_perc)+'%')\n",
    "\n",
    "accuracy_comp.append(acc_perc)\n",
    "precision_comp.append(prec)\n",
    "recall_comp.append(rec)\n",
    "f1score_comp.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4d08bd",
   "metadata": {},
   "source": [
    "###  \n",
    "## XGBoost\n",
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d0991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb = xgb.XGBClassifier()\n",
    "xgb.fit(x_train, y_train)\n",
    "pred = xgb.predict(x_test)\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, predictions))\n",
    "print('\\nClassification Report:\\n\\n',classification_report(y_test, predictions))\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "prec = precision_score(y_test, predictions)\n",
    "rec = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "acc_perc = np.round(acc*100, 2)\n",
    "print('\\nAccuracy=',str(acc_perc)+'%')\n",
    "\n",
    "accuracy_comp.append(acc_perc)\n",
    "precision_comp.append(prec)\n",
    "recall_comp.append(rec)\n",
    "f1score_comp.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941d3ce",
   "metadata": {},
   "source": [
    "###  \n",
    "## KNN\n",
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb4c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(x_train,y_train)\n",
    "predictions = knn.predict(x_test)\n",
    "\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, predictions))\n",
    "print('\\nClassification Report:\\n\\n',classification_report(y_test, predictions))\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "prec = precision_score(y_test, predictions)\n",
    "rec = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "acc_perc = np.round(acc*100, 2)\n",
    "print('\\nAccuracy=',str(acc_perc)+'%')\n",
    "\n",
    "accuracy_comp.append(acc_perc)\n",
    "precision_comp.append(prec)\n",
    "recall_comp.append(rec)\n",
    "f1score_comp.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c46467",
   "metadata": {},
   "source": [
    "###  \n",
    "## Naive Bayes - Bernoulli\n",
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nbb = BernoulliNB()\n",
    "nbb.fit(x_train, y_train)\n",
    "predictions = nbb.predict(x_test)\n",
    "\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, predictions))\n",
    "print('\\nClassification Report:\\n\\n',classification_report(y_test, predictions))\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "prec = precision_score(y_test, predictions)\n",
    "rec = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "acc_perc = np.round(acc*100, 2)\n",
    "print('\\nAccuracy=',str(acc_perc)+'%')\n",
    "\n",
    "accuracy_comp.append(acc_perc)\n",
    "precision_comp.append(prec)\n",
    "recall_comp.append(rec)\n",
    "f1score_comp.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2771f8b9",
   "metadata": {},
   "source": [
    "## SVM\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213dc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "X_train = preprocessing.scale(x_train)\n",
    "X_test = preprocessing.scale(x_test)\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "predictions = svm.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, predictions))\n",
    "print('\\nClassification Report:\\n\\n',classification_report(y_test, predictions))\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "prec = precision_score(y_test, predictions)\n",
    "rec = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "acc_perc = np.round(acc*100, 2)\n",
    "print('\\nAccuracy=',str(acc_perc)+'%')\n",
    "\n",
    "accuracy_comp.append(acc_perc)\n",
    "precision_comp.append(prec)\n",
    "recall_comp.append(rec)\n",
    "f1score_comp.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51986a64",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde15709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf=Perceptron(fit_intercept=False, max_iter=10, tol=None,shuffle=False).fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, predictions))\n",
    "print('\\nClassification Report:\\n\\n',classification_report(y_test, predictions))\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "prec = precision_score(y_test, predictions)\n",
    "rec = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "acc_perc = np.round(acc*100, 2)\n",
    "print('\\nAccuracy=',str(acc_perc)+'%')\n",
    "\n",
    "accuracy_comp.append(acc_perc)\n",
    "precision_comp.append(prec)\n",
    "recall_comp.append(rec)\n",
    "f1score_comp.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef232fd",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efb2b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler() \n",
    "scaler.fit(x_train)  \n",
    "X_train = scaler.transform(x_train)  \n",
    "X_test = scaler.transform(x_test) \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf2 = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf2.fit(X_train, y_train)\n",
    "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
    "              solver='lbfgs')\n",
    "predictions = clf2.predict(X_test)\n",
    "\n",
    "\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, predictions))\n",
    "print('\\nClassification Report:\\n\\n',classification_report(y_test, predictions))\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "prec = precision_score(y_test, predictions)\n",
    "rec = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "acc_perc = np.round(acc*100, 2)\n",
    "print('\\nAccuracy=',str(acc_perc)+'%')\n",
    "\n",
    "accuracy_comp.append(acc_perc)\n",
    "precision_comp.append(prec)\n",
    "recall_comp.append(rec)\n",
    "f1score_comp.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a44314b",
   "metadata": {},
   "source": [
    "## Naive Bayes Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b181f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "X_train = preprocessing.scale(x_train)\n",
    "X_test = preprocessing.scale(x_test)\n",
    "nbb = GaussianNB()\n",
    "nbb.fit(X_train, y_train)\n",
    "predictions = nbb.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, predictions))\n",
    "print('\\nClassification Report:\\n\\n',classification_report(y_test, predictions))\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "prec = precision_score(y_test, predictions)\n",
    "rec = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "acc_perc = np.round(acc*100, 2)\n",
    "print('\\nAccuracy=',str(acc_perc)+'%')\n",
    "\n",
    "accuracy_comp.append(acc_perc)\n",
    "precision_comp.append(prec)\n",
    "recall_comp.append(rec)\n",
    "f1score_comp.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a71049",
   "metadata": {},
   "source": [
    "###  \n",
    "## RESULTS\n",
    "###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5382e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(['Logistic \\nRegression','Decision \\nTree \\nClassifier','Random \\nForest \\nClassfier',\n",
    "         'XGBoost','KNN','Naive \\nBayes-\\nBernoulli','SVM','Perceptron','MLP','Naive \\nBayes-\\nGaussian'],accuracy_comp, 'o-')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy %\")\n",
    "plt.title(\"Comparison Of Accuracy of the used ML models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d484f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models= ['Logistic Regression','Decision Tree Classifier','Random Forest Classfier',\n",
    "         'XGBoost','KNN','Naive Bayes-Bernoulli','SVM','Pereceptron','MLP','Naive \\nBayes-\\nGaussian']\n",
    "print('Accuracies of models are:\\n')\n",
    "for i in range(10) :\n",
    "        print(models[i],':',str(accuracy_comp[i])+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13278f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(['Logistic \\nRegression','Decision \\nTree \\nClassifier','Random \\nForest \\nClassfier',\n",
    "         'XGBoost','KNN','Naive \\nBayes-\\nBernoulli','SVM','Pereceptron','MLP','Naive \\nBayes-\\nGaussian'],precision_comp, 'o-')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Comparison Of Precision of the used ML models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3aef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models= ['Logistic Regression','Decision Tree Classifier','Random Forest Classfier',\n",
    "         'XGBoost','KNN','Naive Bayes-Bernoulli','SVM','Perceptron','MLP','Naive \\nBayes-\\nGaussian']\n",
    "print('Precision of models are:\\n')\n",
    "for i in range(10) :\n",
    "        print(models[i],':',str(precision_comp[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(['Logistic \\nRegression','Decision \\nTree \\nClassifier','Random \\nForest \\nClassfier',\n",
    "         'XGBoost','KNN','Naive \\nBayes-\\nBernoulli','SVM','Perceptron','MLP','Naive \\nBayes-\\nGaussian'],recall_comp, 'o-')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.title(\"Comparison Of Recall of the used ML models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a70ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models= ['Logistic Regression','Decision Tree Classifier','Random Forest Classfier',\n",
    "         'XGBoost','KNN','Naive Bayes-Bernoulli','SVM','Perceptron','MLP','Naive \\nBayes-\\nGaussian']\n",
    "print('Recall of models are:\\n')\n",
    "for i in range(10) :\n",
    "        print(models[i],':',str(recall_comp[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(['Logistic \\nRegression','Decision \\nTree \\nClassifier','Random \\nForest \\nClassfier',\n",
    "         'XGBoost','KNN','Naive \\nBayes-\\nBernoulli','SVM','Perceptron','MLP','Naive \\nBayes-\\nGaussian'],f1score_comp, 'o-')\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"F1-Score\")\n",
    "plt.title(\"Comparison Of F1-Score of the used ML models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d034691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models= ['Logistic Regression','Decision Tree Classifier','Random Forest Classfier',\n",
    "         'XGBoost','KNN','Naive Bayes-Bernoulli','SVM','Perceptron','MLP','Naive \\nBayes-\\nGaussian']\n",
    "print('F1-Score of models are:\\n')\n",
    "for i in range(10) :\n",
    "        print(models[i],':',str(f1score_comp[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8175d1cd",
   "metadata": {},
   "source": [
    "## \n",
    "# END OF PROJECT\n",
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
